{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from wordcloud import WordCloud\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset\n",
    "\n",
    "> Variabel data 1 digunakan untuk skenario pelabelan 1\n",
    "<br>\n",
    "Variabel data 2 digunakan untuk skenario pelabelan 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-21 23:56:14+00:00</td>\n",
       "      <td>1462570580775821313</td>\n",
       "      <td>BukanBuTejo</td>\n",
       "      <td>b'@txtdaritekno Gak usah sok keren data bocor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-21 16:35:53+00:00</td>\n",
       "      <td>1462459765494214661</td>\n",
       "      <td>Syan~GA ALBUM~CEK PINNED</td>\n",
       "      <td>b'@ameamakunai Bisa aja email kak ame bocor tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-21 14:52:08+00:00</td>\n",
       "      <td>1462433655008030720</td>\n",
       "      <td>Ivoox Indonesia</td>\n",
       "      <td>b'Data yang Bocor Berpotensi Disalahgunakan Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-21 14:41:13+00:00</td>\n",
       "      <td>1462430907277529095</td>\n",
       "      <td>ü¶à SUROBOYOFESS üêä</td>\n",
       "      <td>b'Kok data lu bocor yaa?? Hmm isok ae lak mbuj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-21 11:44:12+00:00</td>\n",
       "      <td>1462386359386222594</td>\n",
       "      <td>Aktual Official</td>\n",
       "      <td>b'CISSReC Sebut Data Pribadi Bocor Bisa Diguna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2021-11-14 04:06:06+00:00</td>\n",
       "      <td>1459734360815386626</td>\n",
       "      <td>drama alter</td>\n",
       "      <td>b'SUBES !! HALLO SUBES !! \\n\"Kebenaran akan da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2021-11-14 03:16:26+00:00</td>\n",
       "      <td>1459721858727612419</td>\n",
       "      <td>ÍßÅjajansai~redi sealed memo20+POBÍßÇ</td>\n",
       "      <td>b'@bonvoyajeon Tp kl aku kasih ripiw pasti aku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2021-11-14 00:05:02+00:00</td>\n",
       "      <td>1459673694964379651</td>\n",
       "      <td>Jawa Pos</td>\n",
       "      <td>b'Teror Penagihan hingga Ancaman Data Pribadi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2021-11-13 17:09:33+00:00</td>\n",
       "      <td>1459569133096341506</td>\n",
       "      <td>CanduKenikmatan</td>\n",
       "      <td>b'@rindubulanq @New_boyz_Sby tambahan tips, ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2021-11-13 15:13:05+00:00</td>\n",
       "      <td>1459539823056732161</td>\n",
       "      <td>pan</td>\n",
       "      <td>b'@HybenggQueen @Plussiena @CrimsonHeart___ @V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time                   id  \\\n",
       "0    2021-11-21 23:56:14+00:00  1462570580775821313   \n",
       "1    2021-11-21 16:35:53+00:00  1462459765494214661   \n",
       "2    2021-11-21 14:52:08+00:00  1462433655008030720   \n",
       "3    2021-11-21 14:41:13+00:00  1462430907277529095   \n",
       "4    2021-11-21 11:44:12+00:00  1462386359386222594   \n",
       "..                         ...                  ...   \n",
       "204  2021-11-14 04:06:06+00:00  1459734360815386626   \n",
       "205  2021-11-14 03:16:26+00:00  1459721858727612419   \n",
       "206  2021-11-14 00:05:02+00:00  1459673694964379651   \n",
       "207  2021-11-13 17:09:33+00:00  1459569133096341506   \n",
       "208  2021-11-13 15:13:05+00:00  1459539823056732161   \n",
       "\n",
       "                              username  \\\n",
       "0                          BukanBuTejo   \n",
       "1             Syan~GA ALBUM~CEK PINNED   \n",
       "2                      Ivoox Indonesia   \n",
       "3                     ü¶à SUROBOYOFESS üêä   \n",
       "4                      Aktual Official   \n",
       "..                                 ...   \n",
       "204                        drama alter   \n",
       "205  ÍßÅjajansai~redi sealed memo20+POBÍßÇ   \n",
       "206                           Jawa Pos   \n",
       "207                    CanduKenikmatan   \n",
       "208                                pan   \n",
       "\n",
       "                                                  text  \n",
       "0    b'@txtdaritekno Gak usah sok keren data bocor ...  \n",
       "1    b'@ameamakunai Bisa aja email kak ame bocor tr...  \n",
       "2    b'Data yang Bocor Berpotensi Disalahgunakan Pe...  \n",
       "3    b'Kok data lu bocor yaa?? Hmm isok ae lak mbuj...  \n",
       "4    b'CISSReC Sebut Data Pribadi Bocor Bisa Diguna...  \n",
       "..                                                 ...  \n",
       "204  b'SUBES !! HALLO SUBES !! \\n\"Kebenaran akan da...  \n",
       "205  b'@bonvoyajeon Tp kl aku kasih ripiw pasti aku...  \n",
       "206  b'Teror Penagihan hingga Ancaman Data Pribadi ...  \n",
       "207  b'@rindubulanq @New_boyz_Sby tambahan tips, ka...  \n",
       "208  b'@HybenggQueen @Plussiena @CrimsonHeart___ @V...  \n",
       "\n",
       "[209 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('data bocor-new1.csv', sep=',', encoding='utf-8') \n",
    "data2 = pd.read_csv('data bocor-new1.csv', sep=',', encoding='utf-8') \n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus kolom yang tidak digunakan\n",
    "# variabel data1 digunakan untuk skenario pelabelan 1\n",
    "# variabel data2 digunakan untuk skenario pelabelan 2\n",
    "\n",
    "data1 = data1.drop(data1.columns[[0,1,2]], axis=1)\n",
    "data2 = data2.drop(data2.columns[[0,1,2]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skenario Pelabelan 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation API returned the input string unchanged.\n",
      "Translation API returned the input string unchanged.\n",
      "Translation API returned the input string unchanged.\n",
      "Translation API returned the input string unchanged.\n",
      "Translation API returned the input string unchanged.\n",
      "Translation API returned the input string unchanged.\n",
      "Translation API returned the input string unchanged.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'@txtdaritekno Gak usah sok keren data bocor ...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'@ameamakunai Bisa aja email kak ame bocor tr...</td>\n",
       "      <td>Positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'Data yang Bocor Berpotensi Disalahgunakan Pe...</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'Kok data lu bocor yaa?? Hmm isok ae lak mbuj...</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'CISSReC Sebut Data Pribadi Bocor Bisa Diguna...</td>\n",
       "      <td>Netral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  b'@txtdaritekno Gak usah sok keren data bocor ...  Positif\n",
       "1  b'@ameamakunai Bisa aja email kak ame bocor tr...  Positif\n",
       "2  b'Data yang Bocor Berpotensi Disalahgunakan Pe...   Netral\n",
       "3  b'Kok data lu bocor yaa?? Hmm isok ae lak mbuj...   Netral\n",
       "4  b'CISSReC Sebut Data Pribadi Bocor Bisa Diguna...   Netral"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pelabelan Dengan Textblob\n",
    "\n",
    "def text_blop(txt):\n",
    "    clean = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",txt).split())\n",
    "    text = TextBlob(clean)\n",
    "    \n",
    "    try:\n",
    "      text = text.translate(to=\"en\")\n",
    "      time.sleep(1)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "\n",
    "    if text.sentiment.polarity > 0.0:\n",
    "      hasil = \"Positif\"\n",
    "    \n",
    "    elif text.sentiment.polarity == 0.0:\n",
    "      hasil = \"Netral\"\n",
    "\n",
    "    else:\n",
    "      hasil = \"Negatif\"\n",
    "\n",
    "    return hasil\n",
    "\n",
    "data2['label'] = data2['text'].apply(lambda x: text_blop(x))\n",
    "data2.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "> all skenario preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Punctuationtrain\n",
    "\n",
    "import string\n",
    "import re\n",
    "string.punctuation\n",
    "\n",
    "def remove_punctuation(txt):\n",
    "    '''a function for removing punctuation'''\n",
    "    text = txt[1:]\n",
    "    text = re.sub('@[^\\s]+','',text)\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub(\"#\\S+\", \" \", text)\n",
    "    text = re.sub('\\[.*?\\]', '', str(text))\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‚Äò‚Äô‚Äú‚Äù‚Ä¶]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('  ', '', text)\n",
    "    return text\n",
    "\n",
    "data1['clean'] = data1['text'].apply(lambda x: remove_punctuation(x))\n",
    "data2['clean'] = data2['text'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casefolding\n",
    "\n",
    "def casefolding(txt):\n",
    "    text = str(txt).lower()\n",
    "    return text\n",
    "\n",
    "data1['casefolding'] = data1['clean'].apply(lambda x: casefolding(x))\n",
    "data2['casefolding'] = data2['clean'].apply(lambda x: casefolding(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing\n",
    "def tokenize(kalimat):\n",
    "    text = word_tokenize(kalimat)\n",
    "    return text\n",
    "\n",
    "data1['tokenize'] = data1['casefolding'].apply(lambda x: tokenize(x))\n",
    "data2['tokenize'] = data2['casefolding'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering\n",
    "\n",
    "def stopwords_removal(txt):\n",
    "  filtering = stopwords.words('indonesian', 'english')\n",
    "  x = []\n",
    "  data = []\n",
    "  def myFunc(x):\n",
    "    if x in filtering:\n",
    "      return False\n",
    "    else:\n",
    "      return True\n",
    "  fit = filter(myFunc, txt)\n",
    "  for x in fit:\n",
    "    data.append(x)\n",
    "  return data\n",
    "\n",
    "data1['stopwords'] = data1['tokenize'].apply(lambda x: stopwords_removal(x))\n",
    "data2['stopwords'] = data2['tokenize'].apply(lambda x: stopwords_removal(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "def stemming(txt):\n",
    "  factory = StemmerFactory()\n",
    "  stemmer = factory.create_stemmer()\n",
    "  do = []\n",
    "  for w in txt:\n",
    "    dt = stemmer.stem(w)\n",
    "    do.append(dt)\n",
    "  d_clean = []\n",
    "  d_clean = \" \".join(do)\n",
    "  print(d_clean)\n",
    "  return d_clean\n",
    "\n",
    "data['stemming'] = data['stopwords'].apply(lambda x: stemming(x))\n",
    "\n",
    "data.to_csv('data_clean.csv', index=False)\n",
    "\n",
    "data_clean = pd.read_csv('data_clean.csv', encoding='latin1')\n",
    "data_clean.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "383ff6ec061058c8c67bbbe8229d15dd1c5eb70693263c63cde4fbc9e65720c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
